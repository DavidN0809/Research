{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ab2e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b01312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: soundfile in /home/jupyter/.local/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wavinfo in /home/jupyter/.local/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: lxml~=4.9.2 in /home/jupyter/.local/lib/python3.8/site-packages (from wavinfo) (4.9.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "!pip install wavinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcf6f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (65.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.47.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.23.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyter/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74c3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b84561150749d81d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b84561150749d81d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /dmc/DTLN/models_VTCK_model/logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6002bd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 18:52:31.791584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:31.801411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:31.801674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:31.913312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 18:52:31.924035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:31.924269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:31.924403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:34.084515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:34.084685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:34.084819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 18:52:34.084945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7418 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                [(None, None, 257),  0           ['input_1[0][0]']                \n",
      "                                 (None, None, 257)]                                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 128)    197632      ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 128)    0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, None, 128)    131584      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 257)    33153       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 257)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 257)    0           ['lambda[0][0]',                 \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, None, 512)    0           ['multiply[0][0]',               \n",
      "                                                                  'lambda[0][1]']                 \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 256)    131072      ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " instant_layer_normalization (I  (None, None, 256)   512         ['conv1d[0][0]']                 \n",
      " nstantLayerNormalization)                                                                        \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, None, 128)    197120      ['instant_layer_normalization[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, None, 128)    0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, None, 128)    131584      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 256)    33024       ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 256)    0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, None, 256)    0           ['conv1d[0][0]',                 \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, None, 512)    131072      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, None)         0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 986,753\n",
      "Trainable params: 986,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "Epoch 1/200\n",
      "2023-03-12 18:54:59.846206: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8264  \n",
      "Epoch 1: loss improved from inf to 0.82641, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 264s 134s/step - loss: 0.8264 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -0.2154 \n",
      "Epoch 2: loss improved from 0.82641 to -0.21537, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 298s 177s/step - loss: -0.2154 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -1.1071  \n",
      "Epoch 3: loss improved from -0.21537 to -1.10709, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 336s 103s/step - loss: -1.1071 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -1.9500  \n",
      "Epoch 4: loss improved from -1.10709 to -1.94996, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 285s 136s/step - loss: -1.9500 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -2.7804  \n",
      "Epoch 5: loss improved from -1.94996 to -2.78043, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 314s 166s/step - loss: -2.7804 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -3.5044  \n",
      "Epoch 6: loss improved from -2.78043 to -3.50441, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 351s 226s/step - loss: -3.5044 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -4.1307  \n",
      "Epoch 7: loss improved from -3.50441 to -4.13074, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 647s 292s/step - loss: -4.1307 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -4.6952  \n",
      "Epoch 8: loss improved from -4.13074 to -4.69522, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 459s 237s/step - loss: -4.6952 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -5.2543  \n",
      "Epoch 9: loss improved from -4.69522 to -5.25433, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 310s 154s/step - loss: -5.2543 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -5.6584  \n",
      "Epoch 10: loss improved from -5.25433 to -5.65835, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 269s 126s/step - loss: -5.6584 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -5.9689  \n",
      "Epoch 11: loss improved from -5.65835 to -5.96891, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 274s 107s/step - loss: -5.9689 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -6.1616  \n",
      "Epoch 12: loss improved from -5.96891 to -6.16162, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 263s 127s/step - loss: -6.1616 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -6.5187  \n",
      "Epoch 13: loss improved from -6.16162 to -6.51874, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 342s 165s/step - loss: -6.5187 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -6.6666  \n",
      "Epoch 14: loss improved from -6.51874 to -6.66658, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 293s 136s/step - loss: -6.6666 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -6.9101  \n",
      "Epoch 15: loss improved from -6.66658 to -6.91008, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 316s 129s/step - loss: -6.9101 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -7.0242  \n",
      "Epoch 16: loss improved from -6.91008 to -7.02417, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 310s 163s/step - loss: -7.0242 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -7.2839  \n",
      "Epoch 17: loss improved from -7.02417 to -7.28386, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 293s 130s/step - loss: -7.2839 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -7.4544  \n",
      "Epoch 18: loss improved from -7.28386 to -7.45443, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 278s 131s/step - loss: -7.4544 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -7.5473  \n",
      "Epoch 19: loss improved from -7.45443 to -7.54730, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 288s 108s/step - loss: -7.5473 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -7.9649  \n",
      "Epoch 20: loss improved from -7.54730 to -7.96492, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 266s 126s/step - loss: -7.9649 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.0954  \n",
      "Epoch 21: loss improved from -7.96492 to -8.09538, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 296s 155s/step - loss: -8.0954 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.2624  \n",
      "Epoch 22: loss improved from -8.09538 to -8.26237, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 292s 150s/step - loss: -8.2624 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.5121  \n",
      "Epoch 23: loss improved from -8.26237 to -8.51208, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 299s 120s/step - loss: -8.5121 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.5302  \n",
      "Epoch 24: loss improved from -8.51208 to -8.53022, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 264s 113s/step - loss: -8.5302 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.7339  \n",
      "Epoch 25: loss improved from -8.53022 to -8.73387, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 321s 130s/step - loss: -8.7339 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -8.8903  \n",
      "Epoch 26: loss improved from -8.73387 to -8.89026, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 308s 143s/step - loss: -8.8903 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.0859  \n",
      "Epoch 27: loss improved from -8.89026 to -9.08586, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 272s 143s/step - loss: -9.0859 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.2832  \n",
      "Epoch 28: loss improved from -9.08586 to -9.28315, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 317s 151s/step - loss: -9.2832 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.5074  \n",
      "Epoch 29: loss improved from -9.28315 to -9.50745, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 263s 117s/step - loss: -9.5074 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.5488   \n",
      "Epoch 30: loss improved from -9.50745 to -9.54878, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 270s 137s/step - loss: -9.5488 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.8106  \n",
      "Epoch 31: loss improved from -9.54878 to -9.81060, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 276s 120s/step - loss: -9.8106 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.7341  \n",
      "Epoch 32: loss did not improve from -9.81060\n",
      "2/2 [==============================] - 282s 155s/step - loss: -9.7341 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.0168 \n",
      "Epoch 33: loss improved from -9.81060 to -10.01682, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 266s 113s/step - loss: -10.0168 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -9.9072   \n",
      "Epoch 34: loss did not improve from -10.01682\n",
      "2/2 [==============================] - 277s 141s/step - loss: -9.9072 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.1728 \n",
      "Epoch 35: loss improved from -10.01682 to -10.17280, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 275s 117s/step - loss: -10.1728 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.2164 \n",
      "Epoch 36: loss improved from -10.17280 to -10.21641, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 282s 143s/step - loss: -10.2164 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.4685 \n",
      "Epoch 37: loss improved from -10.21641 to -10.46848, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 270s 116s/step - loss: -10.4685 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.3995  \n",
      "Epoch 38: loss did not improve from -10.46848\n",
      "2/2 [==============================] - 349s 157s/step - loss: -10.3995 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.3726  \n",
      "Epoch 39: loss did not improve from -10.46848\n",
      "2/2 [==============================] - 363s 250s/step - loss: -10.3726 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.5317 \n",
      "Epoch 40: loss improved from -10.46848 to -10.53170, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 653s 203s/step - loss: -10.5317 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.6011  \n",
      "Epoch 41: loss improved from -10.53170 to -10.60114, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 308s 115s/step - loss: -10.6011 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.7737  \n",
      "Epoch 42: loss improved from -10.60114 to -10.77374, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 339s 181s/step - loss: -10.7737 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.7444  \n",
      "Epoch 43: loss did not improve from -10.77374\n",
      "2/2 [==============================] - 324s 167s/step - loss: -10.7444 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.7782  \n",
      "Epoch 44: loss improved from -10.77374 to -10.77822, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 289s 136s/step - loss: -10.7782 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.8842  \n",
      "Epoch 45: loss improved from -10.77822 to -10.88416, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 633s 358s/step - loss: -10.8842 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -10.9552  \n",
      "Epoch 46: loss improved from -10.88416 to -10.95523, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 521s 256s/step - loss: -10.9552 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.0750  \n",
      "Epoch 47: loss improved from -10.95523 to -11.07502, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 376s 162s/step - loss: -11.0750 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.2124  \n",
      "Epoch 48: loss improved from -11.07502 to -11.21241, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 381s 163s/step - loss: -11.2124 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.3355  \n",
      "Epoch 49: loss improved from -11.21241 to -11.33554, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 270s 143s/step - loss: -11.3355 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.1954  \n",
      "Epoch 50: loss did not improve from -11.33554\n",
      "2/2 [==============================] - 268s 123s/step - loss: -11.1954 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.3495  \n",
      "Epoch 51: loss improved from -11.33554 to -11.34949, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 260s 135s/step - loss: -11.3495 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.3349  \n",
      "Epoch 52: loss did not improve from -11.34949\n",
      "2/2 [==============================] - 275s 114s/step - loss: -11.3349 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.3898  \n",
      "Epoch 53: loss improved from -11.34949 to -11.38981, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 267s 117s/step - loss: -11.3898 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.3983  \n",
      "Epoch 54: loss improved from -11.38981 to -11.39833, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 268s 133s/step - loss: -11.3983 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.6031  \n",
      "Epoch 55: loss improved from -11.39833 to -11.60315, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 263s 132s/step - loss: -11.6031 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.4871  \n",
      "Epoch 56: loss did not improve from -11.60315\n",
      "2/2 [==============================] - 267s 131s/step - loss: -11.4871 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.6729  \n",
      "Epoch 57: loss improved from -11.60315 to -11.67286, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 265s 111s/step - loss: -11.6729 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.5240  \n",
      "Epoch 58: loss did not improve from -11.67286\n",
      "2/2 [==============================] - 261s 122s/step - loss: -11.5240 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.7908  \n",
      "Epoch 59: loss improved from -11.67286 to -11.79079, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 274s 110s/step - loss: -11.7908 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.7847  \n",
      "Epoch 60: loss did not improve from -11.79079\n",
      "2/2 [==============================] - 271s 129s/step - loss: -11.7847 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.7904  \n",
      "Epoch 61: loss did not improve from -11.79079\n",
      "2/2 [==============================] - 262s 119s/step - loss: -11.7904 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -11.9605  \n",
      "Epoch 62: loss improved from -11.79079 to -11.96050, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 270s 131s/step - loss: -11.9605 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.0058  \n",
      "Epoch 63: loss improved from -11.96050 to -12.00578, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 264s 141s/step - loss: -12.0058 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.0673  \n",
      "Epoch 64: loss improved from -12.00578 to -12.06733, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 272s 143s/step - loss: -12.0673 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.1713  \n",
      "Epoch 65: loss improved from -12.06733 to -12.17135, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 266s 110s/step - loss: -12.1713 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.1874  \n",
      "Epoch 66: loss improved from -12.17135 to -12.18742, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 274s 122s/step - loss: -12.1874 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.1358  \n",
      "Epoch 67: loss did not improve from -12.18742\n",
      "2/2 [==============================] - 259s 136s/step - loss: -12.1358 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.4641  \n",
      "Epoch 68: loss improved from -12.18742 to -12.46412, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 266s 110s/step - loss: -12.4641 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.2971  \n",
      "Epoch 69: loss did not improve from -12.46412\n",
      "2/2 [==============================] - 263s 106s/step - loss: -12.2971 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.2112  \n",
      "Epoch 70: loss did not improve from -12.46412\n",
      "2/2 [==============================] - 286s 127s/step - loss: -12.2112 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.2888  \n",
      "Epoch 71: loss did not improve from -12.46412\n",
      "2/2 [==============================] - 247s 153s/step - loss: -12.2888 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.4582  \n",
      "Epoch 72: loss did not improve from -12.46412\n",
      "2/2 [==============================] - 275s 151s/step - loss: -12.4582 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.3953  \n",
      "Epoch 73: loss did not improve from -12.46412\n",
      "2/2 [==============================] - 276s 174s/step - loss: -12.3953 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5570  \n",
      "Epoch 74: loss improved from -12.46412 to -12.55697, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 264s 134s/step - loss: -12.5570 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5094  \n",
      "Epoch 75: loss did not improve from -12.55697\n",
      "2/2 [==============================] - 276s 143s/step - loss: -12.5094 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5769  \n",
      "Epoch 76: loss improved from -12.55697 to -12.57687, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 252s 124s/step - loss: -12.5769 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.4289  \n",
      "Epoch 77: loss did not improve from -12.57687\n",
      "2/2 [==============================] - 280s 122s/step - loss: -12.4289 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.6330  \n",
      "Epoch 78: loss improved from -12.57687 to -12.63303, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 271s 128s/step - loss: -12.6330 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5594  \n",
      "Epoch 79: loss did not improve from -12.63303\n",
      "2/2 [==============================] - 260s 116s/step - loss: -12.5594 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5735  \n",
      "Epoch 80: loss did not improve from -12.63303\n",
      "2/2 [==============================] - 274s 128s/step - loss: -12.5735 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5422  \n",
      "Epoch 81: loss did not improve from -12.63303\n",
      "2/2 [==============================] - 271s 146s/step - loss: -12.5422 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7185  \n",
      "Epoch 82: loss improved from -12.63303 to -12.71852, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 264s 100s/step - loss: -12.7185 - lr: 2.5000e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.6265  \n",
      "Epoch 83: loss did not improve from -12.71852\n",
      "2/2 [==============================] - 266s 133s/step - loss: -12.6265 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.8535  \n",
      "Epoch 84: loss improved from -12.71852 to -12.85354, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 274s 140s/step - loss: -12.8535 - lr: 2.5000e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7201  \n",
      "Epoch 85: loss did not improve from -12.85354\n",
      "2/2 [==============================] - 339s 151s/step - loss: -12.7201 - lr: 2.5000e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.5999  \n",
      "Epoch 86: loss did not improve from -12.85354\n",
      "2/2 [==============================] - 390s 139s/step - loss: -12.5999 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.8829  \n",
      "Epoch 87: loss improved from -12.85354 to -12.88289, saving model to ./models_VTCK_model/VTCK_model.h5\n",
      "2/2 [==============================] - 415s 156s/step - loss: -12.8829 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.6973  \n",
      "Epoch 88: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 515s 211s/step - loss: -12.6973 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7512  \n",
      "Epoch 89: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 576s 162s/step - loss: -12.7512 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7019  \n",
      "Epoch 90: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 337s 142s/step - loss: -12.7019 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.8627  \n",
      "Epoch 91: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 376s 179s/step - loss: -12.8627 - lr: 1.2500e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7198  \n",
      "Epoch 92: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 362s 163s/step - loss: -12.7198 - lr: 1.2500e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.6760  \n",
      "Epoch 93: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 321s 178s/step - loss: -12.6760 - lr: 1.2500e-04\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7819  \n",
      "Epoch 94: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 531s 263s/step - loss: -12.7819 - lr: 6.2500e-05\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.8372  \n",
      "Epoch 95: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 351s 185s/step - loss: -12.8372 - lr: 6.2500e-05\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.7227  \n",
      "Epoch 96: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 811s 500s/step - loss: -12.7227 - lr: 6.2500e-05\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - ETA: 0s - loss: -12.8795   \n",
      "Epoch 97: loss did not improve from -12.88289\n",
      "2/2 [==============================] - 1160s 425s/step - loss: -12.8795 - lr: 3.1250e-05\n",
      "2023-03-13 03:45:23.919653: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    }
   ],
   "source": [
    "!python3 run_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49271b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
