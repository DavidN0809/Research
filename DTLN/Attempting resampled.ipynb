{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53ff0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 HDA Intel PCH: ALC897 Analog (hw:0,0), ALSA (2 in, 2 out)\n",
      "   1 HDA Intel PCH: HDMI 0 (hw:0,3), ALSA (0 in, 8 out)\n",
      "   2 HDA Intel PCH: HDMI 1 (hw:0,7), ALSA (0 in, 8 out)\n",
      "   3 HDA Intel PCH: HDMI 2 (hw:0,8), ALSA (0 in, 8 out)\n",
      "   4 HDA Intel PCH: HDMI 3 (hw:0,9), ALSA (0 in, 8 out)\n",
      "   5 HDA NVidia: HDMI 0 (hw:1,3), ALSA (0 in, 8 out)\n",
      "   6 HDA NVidia: HDMI 1 (hw:1,7), ALSA (0 in, 8 out)\n",
      "   7 HDA NVidia: HDMI 2 (hw:1,8), ALSA (0 in, 8 out)\n",
      "   8 HDA NVidia: HDMI 3 (hw:1,9), ALSA (0 in, 8 out)\n",
      "   9 sysdefault, ALSA (128 in, 128 out)\n",
      "  10 front, ALSA (0 in, 2 out)\n",
      "  11 surround40, ALSA (0 in, 2 out)\n",
      "  12 surround51, ALSA (0 in, 2 out)\n",
      "  13 surround71, ALSA (0 in, 2 out)\n",
      "  14 hdmi, ALSA (0 in, 8 out)\n",
      "  15 samplerate, ALSA (128 in, 128 out)\n",
      "  16 speexrate, ALSA (128 in, 128 out)\n",
      "  17 jack, ALSA (2 in, 2 out)\n",
      "  18 pipewire, ALSA (64 in, 64 out)\n",
      "  19 pulse, ALSA (32 in, 32 out)\n",
      "  20 upmix, ALSA (8 in, 8 out)\n",
      "  21 vdownmix, ALSA (6 in, 6 out)\n",
      "  22 dmix, ALSA (0 in, 2 out)\n",
      "* 23 default, ALSA (32 in, 32 out)\n",
      "  24 Built-in Audio Analog Stereo, JACK Audio Connection Kit (4 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7642194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 15:05:18.417792: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-29 15:05:18.419100: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-29 15:05:18.445190: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-29 15:05:18.446048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 15:05:18.908314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "press Return to quit\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "#import tflite_runtime.interpreter as tflite\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "recorded_audio = []\n",
    "\n",
    "# set some parameters\n",
    "block_len_ms = 32 \n",
    "block_shift_ms = 8\n",
    "input_fs = 44100\n",
    "fs_target = 16000\n",
    "\n",
    "# create the interpreters\n",
    "interpreter_1 = tf.lite.Interpreter(model_path='./pretrained_model/model_1.tflite')\n",
    "interpreter_1.allocate_tensors()\n",
    "interpreter_2 = tf.lite.Interpreter(model_path='./pretrained_model/model_2.tflite')\n",
    "interpreter_2.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details_1 = interpreter_1.get_input_details()\n",
    "output_details_1 = interpreter_1.get_output_details()\n",
    "input_details_2 = interpreter_2.get_input_details()\n",
    "output_details_2 = interpreter_2.get_output_details()\n",
    "\n",
    "# create states for the lstms\n",
    "states_1 = np.zeros(input_details_1[1]['shape']).astype('float32')\n",
    "states_2 = np.zeros(input_details_2[1]['shape']).astype('float32')\n",
    "\n",
    "# calculate shift and length\n",
    "block_shift = int(np.round(fs_target * (block_shift_ms / 1000)))\n",
    "block_len = int(np.round(fs_target * (block_len_ms / 1000)))\n",
    "# create buffer\n",
    "in_buffer = np.zeros((block_len)).astype('float32')\n",
    "out_buffer = np.zeros((block_len)).astype('float32')\n",
    "\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "def callback(indata, outdata, frames, time, status):\n",
    "    # buffer and states to global\n",
    "    global in_buffer, out_buffer, states_1, states_2\n",
    "    if status:\n",
    "        print(status)\n",
    "        \n",
    "    # resample input data to 16kHz\n",
    "    indata_resampled = resample(indata, 128)\n",
    "\n",
    "    # write to buffer\n",
    "    in_buffer[:-block_shift] = in_buffer[block_shift:]\n",
    "    in_buffer[-block_shift:] = np.squeeze(indata_resampled)\n",
    "    \n",
    "    # calculate fft of input block\n",
    "    in_block_fft = np.fft.rfft(in_buffer)\n",
    "    in_mag = np.abs(in_block_fft)\n",
    "    in_phase = np.angle(in_block_fft)\n",
    "    \n",
    "    # reshape magnitude to input dimensions\n",
    "    in_mag = np.reshape(in_mag, (1,1,-1)).astype('float32')\n",
    "    \n",
    "    # set tensors to the first model\n",
    "    interpreter_1.set_tensor(input_details_1[1]['index'], states_1)\n",
    "    interpreter_1.set_tensor(input_details_1[0]['index'], in_mag)\n",
    "   \n",
    "    # run calculation \n",
    "    interpreter_1.invoke()\n",
    "    \n",
    "    # get the output of the first block\n",
    "    out_mask = interpreter_1.get_tensor(output_details_1[0]['index']) \n",
    "    states_1 = interpreter_1.get_tensor(output_details_1[1]['index'])   \n",
    "    \n",
    "    # calculate the ifft\n",
    "    estimated_complex = in_mag * out_mask * np.exp(1j * in_phase)\n",
    "    estimated_block = np.fft.irfft(estimated_complex)\n",
    "    \n",
    "    # reshape the time domain block\n",
    "    estimated_block = np.reshape(estimated_block, (1,1,-1)).astype('float32')\n",
    "    \n",
    "    # set tensors to the second block\n",
    "    interpreter_2.set_tensor(input_details_2[1]['index'], states_2)\n",
    "    interpreter_2.set_tensor(input_details_2[0]['index'], estimated_block)\n",
    "    \n",
    "    # run calculation\n",
    "    interpreter_2.invoke()\n",
    "    \n",
    "    # get output tensors\n",
    "    out_block = interpreter_2.get_tensor(output_details_2[0]['index']) \n",
    "    states_2 = interpreter_2.get_tensor(output_details_2[1]['index']) \n",
    "    \n",
    "    # write to buffer\n",
    "    out_buffer[:-block_shift] = out_buffer[block_shift:]\n",
    "    out_buffer[-block_shift:] = np.zeros((block_shift))\n",
    "    out_buffer  += np.squeeze(out_block)\n",
    "    \n",
    "    # output to soundcard\n",
    "    outdata[:] = np.expand_dims(out_buffer[:block_shift], axis=-1)\n",
    "    recorded_audio.append(outdata)\n",
    "\n",
    "\n",
    "#choose the default input and output devices\n",
    "input_device = 23\n",
    "output_device = 23\n",
    "\n",
    "try:\n",
    "    with sd.Stream(device=(input_device, output_device),\n",
    "                   samplerate=input_fs, blocksize=block_shift,\n",
    "                   dtype=np.float32, latency=0.2,\n",
    "                   channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('press Return to quit')\n",
    "        print('#' * 80)\n",
    "        input()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    parser.exit('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03ea31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
